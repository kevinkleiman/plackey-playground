{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e99a7e11-41b0-4df0-82c6-6532548be2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import placekey as pk\n",
    "from placekey.api import PlacekeyAPI\n",
    "import h3 as h3\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d9e5c-9cf6-4e3b-b8ee-c0704cc507e3",
   "metadata": {},
   "source": [
    "# Playing around with the placekey library and API\n",
    "\n",
    "Starting with some initial testing.\n",
    "\n",
    "## Generating a placekey for my apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393a76c2-655d-499f-a2f6-b012db6d1209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin's apartment placekey: @63r-6cv-w6k\n"
     ]
    }
   ],
   "source": [
    "coord = (38.8753221,-77.008219) # Location of my apartment at 1201 Half St. SE\n",
    "\n",
    "apt_placekey = pk.geo_to_placekey(*coord)\n",
    "\n",
    "print(f\"Kevin's apartment placekey: {apt_placekey}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6b1918-4ad3-4f07-aa8d-e0708d75f1e4",
   "metadata": {},
   "source": [
    "\n",
    "<strong><em>Pretty cool! Great runtime.</em></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930fc23f-b240-42ec-b8a0-8371e98c74b4",
   "metadata": {},
   "source": [
    "## Let's start playing around with some real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b21abd9-403b-4f2b-95cc-c92807fc341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For posterity and a possible performance improvement when reading csv\n",
    "blight_column_dtype = { 'X': float, 'Y': float, 'violation_address': str }\n",
    "property_column_dtype = { 'X': float, 'Y': float, 'address': str }\n",
    "\n",
    "# Read both datasets into dataframes\n",
    "blight_violations_df = pd.read_csv('./data/Blight_Violations.csv', low_memory=False, dtype=blight_column_dtype)\n",
    "property_sales_df = pd.read_csv('./data/Property_Sales.csv', low_memory=False, dtype=property_column_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9f1c9-bff4-4ba5-8494-4c955edb85de",
   "metadata": {},
   "source": [
    "### We need to clean this up a bit\n",
    "<strong><em>This dataset has some values we don't necessarily need for the scope of this writeup</em></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8210b22b-f5f0-4b82-ae3c-7b8acdf3f8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---BLIGHT----\n",
      "            X          Y  ticket_id ticket_number  \\\n",
      "0 -83.072568  42.383357      18645   05001700DAH   \n",
      "1 -83.072474  42.383400      18646   05001701DAH   \n",
      "2 -83.115057  42.359928      18648   05001703DAH   \n",
      "3 -83.128037  42.393455      18649   05001704DAH   \n",
      "4 -83.134466  42.389668      18650   05001705DAH   \n",
      "\n",
      "                                      agency_name inspector_name  \\\n",
      "0  Buildings, Safety Engineering & Env Department   Orbie Gailes   \n",
      "1  Buildings, Safety Engineering & Env Department   Orbie Gailes   \n",
      "2  Buildings, Safety Engineering & Env Department   Orbie Gailes   \n",
      "3  Buildings, Safety Engineering & Env Department   Orbie Gailes   \n",
      "4  Buildings, Safety Engineering & Env Department   Orbie Gailes   \n",
      "\n",
      "     violator_name  violation_street_number violation_street_name  \\\n",
      "0        Dean Byrd                      601                  KING   \n",
      "1  Cynthia Roberts                      607                  KING   \n",
      "2    Dannny Barnes                     4066              COLUMBUS   \n",
      "3    Gloria Seldon                     3005              PASADENA   \n",
      "4    Bessie Thomas                     4024              CLEMENTS   \n",
      "\n",
      "  violation_address  ... clean_up_cost  judgment_amount payment_amount  \\\n",
      "0          601 KING  ...           NaN            280.0            0.0   \n",
      "1          607 KING  ...           NaN              0.0            0.0   \n",
      "2     4066 COLUMBUS  ...           NaN              0.0            0.0   \n",
      "3     3005 PASADENA  ...           NaN              0.0            0.0   \n",
      "4     4024 CLEMENTS  ...           NaN              0.0            0.0   \n",
      "\n",
      "  balance_due payment_date      payment_status collection_status   parcelno  \\\n",
      "0       280.0          NaN  NO PAYMENT APPLIED    In Collections  03002390.   \n",
      "1         0.0          NaN      NO PAYMENT DUE               NaN  03002391.   \n",
      "2         0.0          NaN      NO PAYMENT DUE               NaN  14002572.   \n",
      "3         0.0          NaN      NO PAYMENT DUE               NaN  12004708.   \n",
      "4         0.0          NaN      NO PAYMENT DUE               NaN  14005602.   \n",
      "\n",
      "  address_id              updated_at  \n",
      "0   345038.0  2005/02/07 10:22:39+00  \n",
      "1   545718.0  2019/09/16 10:26:00+00  \n",
      "2    71363.0  2005/02/14 17:04:55+00  \n",
      "3   543356.0  2019/09/16 10:26:00+00  \n",
      "4    68819.0  2019/09/16 10:26:00+00  \n",
      "\n",
      "[5 rows x 43 columns] \n",
      "\n",
      "---PROPERTY---\n",
      "            X          Y  sale_id parcel_number            address  \\\n",
      "0 -83.224446  42.388139  3749837     22081917.  14006 GLASTONBURY   \n",
      "1 -83.210323  42.438587  4210008     22061697.  19951 ASBURY PARK   \n",
      "2 -83.209319  42.415134  4210338     22061878.  16881 ASBURY PARK   \n",
      "3 -83.161543  42.351916  3775822     18004875.      10322 TIREMAN   \n",
      "4 -83.074014  42.346942  3663543     06005448.       4158 LINCOLN   \n",
      "\n",
      "   street_number street_prefix  street_name unit_number  sale_number  ...  \\\n",
      "0          14006           NaN  GLASTONBURY         NaN            1  ...   \n",
      "1          19951           NaN       ASBURY         NaN            1  ...   \n",
      "2          16881           NaN       ASBURY         NaN            1  ...   \n",
      "3          10322           NaN      TIREMAN         NaN            1  ...   \n",
      "4           4158           NaN      LINCOLN         NaN            1  ...   \n",
      "\n",
      "                    grantor                   grantee  liber_page  \\\n",
      "0            JOHNSON, KEVIN        NEWBERRY, TARSHISH  51986-1417   \n",
      "1            COFFEY, MARIAH              REAL TC LLC    52044-644   \n",
      "2         MCDOWELL, KAREN R  MCQUEEN, WILLIE & BESSIE   51982:634   \n",
      "3  MOTOWN PROPERTY SERVICES                H.I.G. LLC   51992-709   \n",
      "4      CITY OF DETROIT-P&DD                CRUSE, ZAC   L.1,P.308   \n",
      "\n",
      "        term_of_sale            sale_verification sale_instrument  \\\n",
      "0    03-ARM'S LENGTH  PROPERTY TRANSFER AFFIDAVIT             PTA   \n",
      "1  21-NOT USED/OTHER  PROPERTY TRANSFER AFFIDAVIT             PTA   \n",
      "2  21-NOT USED/OTHER  PROPERTY TRANSFER AFFIDAVIT             PTA   \n",
      "3  21-NOT USED/OTHER  PROPERTY TRANSFER AFFIDAVIT             PTA   \n",
      "4  21-NOT USED/OTHER  PROPERTY TRANSFER AFFIDAVIT             PTA   \n",
      "\n",
      "  property_transferred_percentage property_class_code  \\\n",
      "0                           100.0               401.0   \n",
      "1                             0.0               401.0   \n",
      "2                           100.0               401.0   \n",
      "3                             0.0               401.0   \n",
      "4                             0.0               402.0   \n",
      "\n",
      "   economic_condition_factor_neigh  ESRI_OID  \n",
      "0                            1R132         1  \n",
      "1                            2R201         2  \n",
      "2                            1R117         3  \n",
      "3                            7R719         4  \n",
      "4                            6R608         5  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"---BLIGHT----\\n\", blight_violations_df.head(), \"\\n\\n---PROPERTY---\\n\", property_sales_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed47dc-d4d0-4626-9b70-09e83b9eb928",
   "metadata": {},
   "source": [
    "### We really only want the (x, y) coordinates plus the stringified full address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb85d6dc-597d-4dcb-bad0-303074cc2a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X          Y violation_address\n",
      "0 -83.072568  42.383357          601 KING\n",
      "1 -83.072474  42.383400          607 KING\n",
      "2 -83.115057  42.359928     4066 COLUMBUS\n",
      "3 -83.128037  42.393455     3005 PASADENA\n",
      "4 -83.134466  42.389668     4024 CLEMENTS\n",
      "           X          Y            address\n",
      "0 -83.224446  42.388139  14006 GLASTONBURY\n",
      "1 -83.210323  42.438587  19951 ASBURY PARK\n",
      "2 -83.209319  42.415134  16881 ASBURY PARK\n",
      "3 -83.161543  42.351916      10322 TIREMAN\n",
      "4 -83.074014  42.346942       4158 LINCOLN\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns not defined in the dtype dictionary above\n",
    "blight_violations_df = blight_violations_df.filter(blight_column_dtype.keys()).truncate(before=0, after=1000)\n",
    "property_sales_df = property_sales_df.filter(property_column_dtype.keys()).truncate(before=0, after=1000)\n",
    "\n",
    "# Let's take a look at the results\n",
    "print(blight_violations_df.head())\n",
    "print(property_sales_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ae062-7910-4508-b8fe-de17102ccac9",
   "metadata": {},
   "source": [
    "\n",
    "<strong><em>Sweet! Now we have some cleaner data to work with and really harness PlaceKey's API.</em></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36fb7994-b3b0-40ad-a528-d6c638781f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key from environment variables\n",
    "placekey_api_key = os.getenv('PLACEKEY_API_KEY')\n",
    "\n",
    "# Create connection to Placekey API\n",
    "pk_api = PlacekeyAPI(placekey_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9500ae22-4da8-4ab5-a73a-66d331dfd74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X          Y violation_address\n",
      "0 -83.072568  42.383357          601 KING\n",
      "1 -83.072474  42.383400          607 KING\n",
      "2 -83.115057  42.359928     4066 COLUMBUS\n",
      "3 -83.128037  42.393455     3005 PASADENA\n",
      "4 -83.134466  42.389668     4024 CLEMENTS\n",
      "BLIGHT:  1001 PROPERTY:  1001\n"
     ]
    }
   ],
   "source": [
    "# We need to reset the index to get our query_id, then rename the columns to conform\n",
    "# with Placekey's query params so let's write a function to handle this\n",
    "\n",
    "def df_to_api_query(df: pd.DataFrame, column_map: dict):\n",
    "    # Renaming our columns\n",
    "    df = df.reset_index().rename(columns=column_map)\n",
    "\n",
    "    # Setting default region and country code (we assume Michigan and US for this particular dataset)\n",
    "    df['region'] = 'MI'\n",
    "    df['iso_country_code'] = 'US'\n",
    "\n",
    "    # We need to convert query_id to string to conform with Placekey's API docs\n",
    "    df['query_id'] = df['query_id'].astype(str)\n",
    "\n",
    "    # Return jsonified dataframe\n",
    "    return json.loads(df.to_json(orient='records'))\n",
    "\n",
    "\n",
    "# Use our function to convert dataframes to json\n",
    "blight_violations_json = df_to_api_query(df=blight_violations_df, \\\n",
    "                                         column_map={'index': 'query_id', 'violation_address': 'street_address', 'X': 'longitude', 'Y': 'latitude'})\n",
    "property_sales_json = df_to_api_query(df=property_sales_df, \\\n",
    "                                      column_map={'index': 'query_id', 'address': 'street_address', 'X': 'longitude', 'Y': 'latitude'})\n",
    "\n",
    "# Let's check our work\n",
    "print(blight_violations_df.head())\n",
    "\n",
    "# Finally, let's make this API call\n",
    "blight_response = pk_api.lookup_placekeys(blight_violations_json)\n",
    "property_response = pk_api.lookup_placekeys(property_sales_json)\n",
    "\n",
    "\n",
    "print('BLIGHT: ', len(blight_response), 'PROPERTY: ', len(property_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1373de-71dc-4eeb-ab90-3450b78bcef8",
   "metadata": {},
   "source": [
    "<strong><em>Wowza!! That was pretty cool. Obviously, a more records, this would take quite a while.</em></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b1d83-318d-46e3-b592-3045f927e563",
   "metadata": {},
   "source": [
    "<strong><em>In the long run, though, runtime will be much more efficient when joining these datasets</em></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e67a1c-83ea-4782-90d3-1d4b35fdf1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can convert the API response to a dataframe\n",
    "blight_pk_df = pd.read_json(json.dumps(blight_response), dtype={'query_id': str})\n",
    "property_pk_df = pd.read_json(json.dumps(property_response), dtype={'query_id': str})\n",
    "\n",
    "# Let's create another function to handle merging the placekey response with the original df\n",
    "def merge_placekey_with_df(pk_df: pd.DataFrame, org_df: pd.DataFrame):\n",
    "    org_df = org_df.reset_index()\n",
    "    org_df['index'] = org_df['index'].astype(str)\n",
    "    \n",
    "    with_pk_df = pd.merge(org_df, pk_df, left_on=\"index\", right_on=\"query_id\", how='left')\n",
    "    with_pk_df = with_pk_df.drop('error', axis=1)\n",
    "\n",
    "    return with_pk_df\n",
    "\n",
    "blight_pk_merged = merge_placekey_with_df(blight_pk_df, blight_violations_df)\n",
    "property_pk_merged = merge_placekey_with_df(property_pk_df, property_sales_df)\n",
    "\n",
    "# Finally, lets outer join these two data frames to really harness the power of placekey\n",
    "joined_blight_property_df = blight_pk_merged.merge(property_pk_merged, how='inner', on='placekey')\n",
    "\n",
    "# Runtime is great when joining on placekey!\n",
    "joined_blight_property_df.to_csv('joined.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c492fb1-4e06-4164-809c-8a0b37f768ca",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "<strong><em>While calling Placekey's API with 1M+ records can be time consuming (understandable), the speed of joining datasets with a placekey seems to be worth it! Pretty cool experiment! When looking at the joined dataset, we can see that addresses with similar/same longitude and latitude (but different addresses) have identical placekeys! Really interesting!\n",
    "</em></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3745b388-0dad-40a4-8e50-74e12907b27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
